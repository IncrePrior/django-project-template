# Docker-compose configuration for production

version: '2.1'

services:
  django:
    build:
      context: .
      dockerfile: Dockerfile-django.production
    env_file: .env
    container_name: {{cookiecutter.repo_name}}_django
    restart: unless-stopped
    volumes:
      - "/var/lib/docker-nginx/files/{{cookiecutter.repo_name}}/assets:/files/assets"
      - "/var/log/{{cookiecutter.repo_name}}:/var/log/{{cookiecutter.repo_name}}"
    # For some reason the command also has to be specified here, otherwise the entrypoint+command combination won't
    #  work.
    entrypoint: /usr/bin/wait-for-it.sh postgres:5432 -t 60 --
    command: gunicorn {{cookiecutter.repo_name}}.wsgi:application --workers 2 --bind :80
    networks:
      - default
      - {{cookiecutter.repo_name}}_nginx
      - {{cookiecutter.repo_name}}_postgres
    depends_on:
      - redis
    external_links:
      - postgres-{{cookiecutter.postgres_version}}:postgres
  {%- if cookiecutter.frontend_style == 'spa' %}

  node:
    build:
      context: .
      dockerfile: Dockerfile-node.production
    env_file: .env
    container_name: {{cookiecutter.repo_name}}_node
    restart: unless-stopped
    command: yarn start
    volumes:
      - "/var/lib/docker-nginx/files/{{cookiecutter.repo_name}}/app/assets:/files/assets"
      - "/var/log/{{cookiecutter.repo_name}}:/var/log/{{cookiecutter.repo_name}}"
    networks:
      - default
      - {{cookiecutter.repo_name}}_nginx
  {%- endif %}

  {%- if cookiecutter.include_celery == 'yes' %}

  celery:
    build:
      context: .
      dockerfile: Dockerfile-django.production
    env_file: .env
    restart: unless-stopped
    volumes:
      - "/var/lib/docker-nginx/files/{{cookiecutter.repo_name}}/media:/files/media"
      - "/var/log/{{cookiecutter.repo_name}}:/var/log/{{cookiecutter.repo_name}}"
    networks:
      - default
      - {{cookiecutter.repo_name}}_postgres
    depends_on:
      - redis
    external_links:
      - postgres-{{cookiecutter.postgres_version}}:postgres
    entrypoint: /usr/bin/wait-for-it.sh postgres:5432 -t 60 --
    command: celery --app {{cookiecutter.repo_name}} worker --autoscale 6,2 --loglevel INFO

  celery_beat:
    build:
      context: .
      dockerfile: Dockerfile-django.production
    env_file: .env
    container_name: {{cookiecutter.repo_name}}_celery_beat
    restart: unless-stopped
    volumes:
      - "/var/lib/docker-{{cookiecutter.repo_name}}/celery:/celery"
      - "/var/log/{{cookiecutter.repo_name}}:/var/log/{{cookiecutter.repo_name}}"
    networks:
      - default
    depends_on:
      - redis
    # Disable pidfile by specifying an empty one. We used fixed container_name which provides single-running-process
    #  guarantee and the lack of pidfile ensures that Celery Beat starts even if the Docker container was killed and
    #  then restarted (in which case the pidfile would still be present).
    command: celery --app {{cookiecutter.repo_name}} beat --loglevel INFO --logfile /var/log/{{cookiecutter.repo_name}}/celery-beat.log --pidfile= --schedule /celery/celerybeat-schedule
  {%- endif %}

  redis:
    image: redis:4.0.10-alpine
    restart: unless-stopped
    sysctls:
      # To allow maintaining TCP backlog setting that defaults to 511
      net.core.somaxconn: 512
    volumes:
      - "/var/lib/docker-{{cookiecutter.repo_name}}/redis:/data"
    networks:
      - default

# NB: These networks must be created by ansible and contain the global nginx/postgres containers.
# Keep it in sync with ansible/roles/deploy/tasks/main.yml!
networks:
  default:
    external:
      name: {{cookiecutter.repo_name}}_default
  {{cookiecutter.repo_name}}_nginx:
    external: true
  {{cookiecutter.repo_name}}_postgres:
    external: true
